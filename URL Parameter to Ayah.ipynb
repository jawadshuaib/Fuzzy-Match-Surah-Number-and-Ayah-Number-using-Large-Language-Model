{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bede3bb",
   "metadata": {},
   "source": [
    "# Fuzzy Match URL Param to Surah:Ayah Format using Large Language Model (GPT-3.5)\n",
    "\n",
    "A user could type Surah:Ayah in the url in a number of ways. We need to be able to extract the surah and ayah from their request. \n",
    "\n",
    "The reason we are not using RegExp here is because there are many different ways the user may enter the Surah and Ayah number, so we can instead infer it from the Large Language Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96d52db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbfeef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1db6cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2f70f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\"keys/.env\")\n",
    "\n",
    "openai_api_key = os.getenv('OPEN_API_KEY_FOR_FUZZY_MATCH_SURAH_AYAH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7c00d4",
   "metadata": {},
   "source": [
    "A user enters the following Surah and Ayah number in the URL. We need to be able to extract the Surah/Ayah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "253c128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the URL Param entered by the user. Note that it can be changed to other formats and the LLM will \n",
    "# still be able to infer it. For example, change 2/36 to 2-36 or 2:36, etc\n",
    "user_prompt = \"2/36\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9241ae72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To help construct our Chat Messages\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# We will be using a chat model, defaults to gpt-3.5-turbo\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# To parse outputs and get structured data back\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0, model_name='gpt-3.5-turbo', openai_api_key=openai_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7488553e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The schema I want out\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"surah_number\", description=\"Surah number from the Quran\"),\n",
    "    ResponseSchema(name=\"ayah_number\", description=\"Ayah number from the Quran\")\n",
    "]\n",
    "\n",
    "# The parser that will look for the LLM output in my schema and return it back to me\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee412f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"surah_number\": string  // Surah number from the Quran\n",
      "\t\"ayah_number\": string  // Ayah number from the Quran\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# The format instructions that LangChain makes. Let's look at them\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63db1144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The prompt template that brings it all together\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[\n",
    "        HumanMessagePromptTemplate.from_template(\"You will be given a surah number and ayah number for the Quran. \\n \\\n",
    "                                                  Extract the surah number and aya number. If no match is found, \\n \\\n",
    "                                                  just output surah number as 0 and ayah number as 0. \\n \\\n",
    "                                                  {format_instructions}\\n{user_prompt}\")  \n",
    "    ],\n",
    "    input_variables=[\"user_prompt\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2bab5f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You will be given a surah number and ayah number for the Quran. \n",
      "                                                   Extract the surah number and aya number. If no match is found, \n",
      "                                                   just output surah number as 0 and ayah number as 0. \n",
      "                                                   The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"surah_number\": string  // Surah number from the Quran\n",
      "\t\"ayah_number\": string  // Ayah number from the Quran\n",
      "}\n",
      "```\n",
      "2/36\n"
     ]
    }
   ],
   "source": [
    "query = prompt.format_prompt(user_prompt=user_prompt)\n",
    "print (query.messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "abf7525b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'surah_number': '2', 'ayah_number': '36'}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "prompt_output = chat_model(query.to_messages())\n",
    "formatted_output = output_parser.parse(prompt_output.content)\n",
    "\n",
    "print (formatted_output)\n",
    "print (type(formatted_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "91b57e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'surah_number': '2', 'ayah_number': '36'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
